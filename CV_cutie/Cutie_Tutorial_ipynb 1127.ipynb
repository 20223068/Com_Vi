{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJhb2__PEXpe"
      },
      "source": [
        "# Putting the Object Back into Video Object Segmentation\n",
        "# Colab Demo\n",
        "\n",
        "[[arXiv]](https://arxiv.org/abs/2310.12982) [[PDF]](https://arxiv.org/pdf/2310.12982.pdf) [[Code]](https://github.com/hkchengrex/Cutie) [[Project Page]](https://hkchengrex.github.io/Cutie/)\n",
        "\n",
        "![title](https://camo.githubusercontent.com/84482c6f65f93339699387c6880640bf5213583ceca2f5658c423dc1d68ab8a9/68747470733a2f2f696d6775722e636f6d2f364b3742675a372e706e67)\n",
        "\n",
        "![overview](https://camo.githubusercontent.com/53c8662cecfbd61e1e06d08cfe086333cbcb365170ad56f6a62e9d55aa7a918b/68747470733a2f2f696d6775722e636f6d2f707835673433372e6a7067)\n",
        "\n",
        "You can make a copy of this notebook to change the input video or mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "MWGdN7XCSYSm",
        "outputId": "c8d63f9b-b124-484e-a3ac-05ab94384ce0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "A UTF-8 locale is required. Got ANSI_X3.4-1968",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-e937af9eb6c3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvidia-smi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print('Using GPU')\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  print('CUDA not available. Please connect to a GPU instance if possible.')\n",
        "  device = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y6gsK0lGUio"
      },
      "source": [
        "# Get our code and install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "vOvqzVtiGZxi",
        "outputId": "5300f2eb-323f-47e5-aede-2812514850f1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "A UTF-8 locale is required. Got ANSI_X3.4-1968",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-04c3fd5f6eb6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/hkchengrex/Cutie.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cutie'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -e .'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hkchengrex/Cutie.git\n",
        "%cd Cutie\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AekycKjXRlQ"
      },
      "source": [
        "# Then restart the runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8NrncykF0lo"
      },
      "source": [
        "# Download the pretrained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp63HPm9I2XV"
      },
      "outputs": [],
      "source": [
        "%cd /content/Cutie\n",
        "!python cutie/utils/download_models.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PWAl-8BUgRp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVIQ83wmVwKB"
      },
      "outputs": [],
      "source": [
        "!pip install hydra-core --upgrade\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_bUsmaYJESK"
      },
      "source": [
        "# Basic setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgeOY8LNYoV9"
      },
      "outputs": [],
      "source": [
        "%cd /content/Cutie/\n",
        "\n",
        "from os import path\n",
        "import logging\n",
        "from omegaconf import DictConfig\n",
        "import hydra\n",
        "from hydra.core.hydra_config import HydraConfig\n",
        "from omegaconf import open_dict\n",
        "from hydra import compose, initialize\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from cutie.inference.data.vos_test_dataset import VOSTestDataset\n",
        "from cutie.inference.data.burst_test_dataset import BURSTTestDataset\n",
        "from cutie.model.cutie import CUTIE\n",
        "from cutie.inference.inference_core import InferenceCore\n",
        "from cutie.inference.utils.results_utils import ResultSaver, make_zip\n",
        "from cutie.inference.utils.burst_utils import BURSTResultHandler\n",
        "from cutie.inference.utils.args_utils import get_dataset_cfg\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "GlobalHydra.instance().clear()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  initialize(version_base='1.3.2', config_path=\"cutie/config\", job_name=\"eval_config\")\n",
        "  cfg = compose(config_name=\"eval_config\")\n",
        "\n",
        "  with open_dict(cfg):\n",
        "    cfg['weights'] = './weights/cutie-base-mega.pth'\n",
        "\n",
        "  data_cfg = get_dataset_cfg(cfg)\n",
        "\n",
        "  # Load the network weights\n",
        "  cutie = CUTIE(cfg).cuda().eval()\n",
        "  model_weights = torch.load(cfg.weights)\n",
        "  cutie.load_weights(model_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzq2D_OBM3iP"
      },
      "source": [
        "# Load some data\n",
        "\n",
        "(Source: https://www.youtube.com/watch?v=FTcjzaqL0pE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4jU5ui-XGlQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 파일 이름 지정\n",
        "video_name = 'rabbit1.mp4'\n",
        "mask_name = 'rabbit1_mask.png'\n",
        "#/content/Cutie/examples/masks/rabbit/rabbit1_mask.png\n",
        "#경로 설정\n",
        "video_path = f'/content/drive/MyDrive/{video_name}'\n",
        "image_path = f'/content/drive/MyDrive/{mask_name}'\n",
        "\n",
        "'''\n",
        "# 파일 이름 지정\n",
        "video_name = 'rabbit1.mp4'\n",
        "mask_name = 'rabbit_1_mask2.jpg'\n",
        "#/content/Cutie/examples/masks/rabbit/rabbit1_mask.png\n",
        "#경로 설정\n",
        "video_path = f'/content/drive/MyDrive/{video_name}'\n",
        "image_path = f'/content/drive/MyDrive/{mask_name}'\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYxr-E9UPeNy"
      },
      "source": [
        "# Preview the video and first-frame annotation\n",
        "\n",
        "The first frame mask is a PNG with a color palette."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Esqjhs4Pg3P"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(open(video_path, 'rb').read()).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsSMUSC2Pq-R"
      },
      "outputs": [],
      "source": [
        "import IPython.display\n",
        "image_path = '/content/drive/MyDrive/rabbit1_frame.jpg'\n",
        "IPython.display.Image(image_path, width=400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAOCrqAwa0yL"
      },
      "source": [
        "## Convert the mask to a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLEi4Ui-a1F3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "mask_path = '/content/drive/MyDrive/rabbit1_mask.jpg'\n",
        "# Use Image.open to open the image file\n",
        "mask = np.array(Image.open(mask_path))\n",
        "valid_values = [1, 2, 3]\n",
        "mask = np.isin(mask, valid_values).astype(np.uint8)\n",
        "  '''\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "mask_path = '/content/drive/MyDrive/rabbit1_mask.jpg'\n",
        "# Use Image.open to open the image file\n",
        "mask = np.array(Image.open(mask_path))\n",
        "valid_values = [1, 2, 3]\n",
        "mask = np.isin(mask, valid_values).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVCnhbCN4ogl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "video_name = '/content/drive/MyDrive/rabbit1.mp4'\n",
        "\n",
        "# Check if the video file exists\n",
        "if not os.path.exists(video_name):\n",
        "    print(f\"Error: Video file '{video_name}' does not exist.\")\n",
        "else:\n",
        "    print(f\"Video file '{video_name}' found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVyVdpvyThqJ"
      },
      "source": [
        "# Propagte frame-by-frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPKtkXP7FELW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from gui.interactive_utils import image_to_torch, torch_prob_to_numpy_mask, index_numpy_to_one_hot_torch, overlay_davis\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "device = 'cuda'\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 마스크에서 객체 개수 계산 (예시: 마스크에 고유한 값에서 배경(0)을 제외한 개수)\n",
        "num_objects = len(np.unique(mask)) - 1  # 배경 제외\n",
        "\n",
        "print('num_objects :',num_objects) #이거 직접입력 기능 넣으면 좋겟다\n",
        "\n",
        "processor = InferenceCore(cutie, cfg=cfg)\n",
        "cap = cv2.VideoCapture(video_name)\n",
        "\n",
        "# You can change these two numbers\n",
        "frames_to_propagate = 200\n",
        "visualize_every = 20\n",
        "\n",
        "current_frame_index = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.ndimage import binary_dilation  # 마스크 확장에 사용\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.inference_mode():\n",
        "    with torch.amp.autocast(\"cuda\", enabled=True):  # 최신 방식으로 수정\n",
        "        while cap.isOpened():\n",
        "            # 프레임을 한 장씩 읽기\n",
        "            _, frame = cap.read()\n",
        "            if frame is None or current_frame_index > frames_to_propagate:\n",
        "                break\n",
        "\n",
        "            # NumPy 배열을 PyTorch 텐서로 변환\n",
        "            frame_torch = image_to_torch(frame, device=device)\n",
        "\n",
        "            if current_frame_index == 0:\n",
        "                # 초기 마스크 확인 및 시각화\n",
        "                print(\"Initial Mask Shape:\", mask.shape)  # (H, W, C) 또는 (H, W)\n",
        "                print(\"Unique Values in Mask:\", np.unique(mask))  # [0, 1] 등\n",
        "                plt.imshow(mask, cmap=\"gray\")\n",
        "                plt.title(\"Initial Mask\")\n",
        "                plt.show()\n",
        "\n",
        "                # 마스크를 단일 채널로 변환 (첫 번째 채널 사용)\n",
        "                if mask.ndim == 3 and mask.shape[2] == 3:  # RGB일 경우\n",
        "                    mask = mask[:, :, 0]  # 단일 채널로 변환\n",
        "                elif mask.ndim != 2:  # 2D가 아닌 경우 예외 처리\n",
        "                    raise ValueError(\"mask는 2D 단일 채널 배열이어야 합니다.\")\n",
        "\n",
        "                # 마스크 확장 (필요하면 활성화)\n",
        "                mask = binary_dilation(mask, iterations=3).astype(mask.dtype)  # 확장 정도는 조정 가능\n",
        "                print(\"Mask Shape After Dilation:\", mask.shape)\n",
        "\n",
        "                # 변환 후 Shape 확인\n",
        "                print(\"Converted Mask Shape (Single Channel):\", mask.shape)\n",
        "\n",
        "                # One-Hot 인코딩 수행\n",
        "                mask_torch = index_numpy_to_one_hot_torch(mask, num_objects + 1).to(device)\n",
        "\n",
        "                # One-Hot 변환된 텐서 확인 및 시각화\n",
        "                print(\"Mask Tensor Shape (One-Hot):\", mask_torch.shape)  # (C, H, W)\n",
        "                for i in range(mask_torch.shape[0]):  # 각 채널 확인\n",
        "                    plt.imshow(mask_torch[i].cpu().numpy(), cmap=\"gray\")\n",
        "                    plt.title(f\"One-Hot Channel {i}\")\n",
        "                    plt.show()\n",
        "\n",
        "                # 채널 확인 및 배경 제외\n",
        "                if mask_torch.shape[0] != num_objects + 1:\n",
        "                    raise ValueError(\"One-Hot 인코딩된 mask_torch의 채널 수가 올바르지 않습니다.\")\n",
        "\n",
        "                # 배경을 제외한 마스크 전달\n",
        "                prediction = processor.step(frame_torch, mask_torch[1:], idx_mask=False)\n",
        "            else:\n",
        "                # 다음 프레임에서는 propagate만 수행\n",
        "                prediction = processor.step(frame_torch)\n",
        "\n",
        "            # 예측 결과를 NumPy 배열로 변환\n",
        "            prediction = torch_prob_to_numpy_mask(prediction)\n",
        "\n",
        "            # 시각화 주기마다 결과를 출력\n",
        "            if current_frame_index % visualize_every == 0:\n",
        "                visualization = overlay_davis(frame, prediction)\n",
        "                display(Image.fromarray(visualization))\n",
        "\n",
        "            # 현재 프레임 인덱스 증가\n",
        "            current_frame_index += 1\n"
      ],
      "metadata": {
        "id": "nVKVa6rMaUPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LlO50fyFES1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#마스킹 단색이 아닌 3채널일때\n",
        "with torch.inference_mode():\n",
        "    with torch.amp.autocast(\"cuda\", enabled=True):  # torch.cuda.amp.autocast 대신 새 방식 사용\n",
        "        while cap.isOpened():\n",
        "            # 프레임을 한 장씩 읽기\n",
        "            _, frame = cap.read()\n",
        "            if frame is None or current_frame_index > frames_to_propagate:\n",
        "                break\n",
        "\n",
        "            # NumPy 배열을 PyTorch 텐서로 변환\n",
        "            frame_torch = image_to_torch(frame, device=device)\n",
        "\n",
        "            if current_frame_index == 0:\n",
        "                # 초기 마스크 확인 및 디버깅\n",
        "                print(\"Initial Mask Shape:\", mask.shape)  # (720, 1280, 3)\n",
        "                print(\"Unique Values in Mask:\", np.unique(mask))  # [0, 1]\n",
        "\n",
        "                # 마스크를 단일 채널로 변환 (첫 번째 채널 사용)\n",
        "                if mask.ndim == 3 and mask.shape[2] == 3:  # RGB일 경우\n",
        "                    mask = mask[:, :, 0]  # 단일 채널로 변환\n",
        "                elif mask.ndim != 2:  # 2D가 아닌 경우 예외 처리\n",
        "                    raise ValueError(\"mask는 2D 단일 채널 배열이어야 합니다.\")\n",
        "\n",
        "                # 변환 후 Shape 확인\n",
        "                print(\"Converted Mask Shape (Single Channel):\", mask.shape)\n",
        "\n",
        "                # One-Hot 인코딩 수행\n",
        "                mask_torch = index_numpy_to_one_hot_torch(mask, num_objects + 1).to(device)\n",
        "\n",
        "                # One-Hot 변환된 텐서 확인\n",
        "                print(\"Mask Tensor Shape (One-Hot):\", mask_torch.shape)  # (C, H, W)\n",
        "\n",
        "                # 채널 확인 및 배경 제외\n",
        "                if mask_torch.shape[0] != num_objects + 1:\n",
        "                    raise ValueError(\"One-Hot 인코딩된 mask_torch의 채널 수가 올바르지 않습니다.\")\n",
        "\n",
        "                # 배경을 제외한 마스크 전달\n",
        "                prediction = processor.step(frame_torch, mask_torch[1:], idx_mask=False)\n",
        "            else:\n",
        "                # 다음 프레임에서는 propagate만 수행\n",
        "                prediction = processor.step(frame_torch)\n",
        "\n",
        "            # 예측 결과를 NumPy 배열로 변환\n",
        "            prediction = torch_prob_to_numpy_mask(prediction)\n",
        "\n",
        "            # 시각화 주기마다 결과를 출력\n",
        "            if current_frame_index % visualize_every == 0:\n",
        "                visualization = overlay_davis(frame, prediction)\n",
        "                display(Image.fromarray(visualization))\n",
        "\n",
        "            # 현재 프레임 인덱스 증가\n",
        "            current_frame_index += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQmwc6jGFEVt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aLw0mTJFEYN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TpMVZ8SFEav"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}